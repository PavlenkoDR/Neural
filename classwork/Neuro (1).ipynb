{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavlenkoDR/Neural/blob/master/classwork/Neuro%20(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jM3XcmKrOWqf"
      },
      "source": [
        "Для распознавания используется предварительно обученная сверточная нейронная сеть VGG16.\n",
        "\n",
        "Перед использованием необходимо скачать и подготовить данные для обучения, проверки и тестирования."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6BxI_pzOvhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "#!unzip -uq \"/content/gdrive/My Drive/DataSet/train/train.zip\" -d \"/content/gdrive/My Drive/DataSet/train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LAUFU7eFOWqd",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.applications import VGG16\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from tensorflow.python.keras.applications import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B_c_90StOWqb",
        "colab": {}
      },
      "source": [
        "# Каталог с данными для обучения\n",
        "test_dir = '/content/gdrive/My Drive/DataSet/test'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = '/content/gdrive/My Drive/DataSet/val'\n",
        "# Каталог с данными для тестирования\n",
        "train_dir = '/content/gdrive/My Drive/DataSet/train/train'\n",
        "# Размеры изображения\n",
        "img_width, img_height = 150, 150\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Размер мини-выборки\n",
        "batch_size = 32\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 2565\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 100\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4wpwBRFGOWqa"
      },
      "source": [
        "Загружаем предварительно обученную нейронную сеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdLrA7YkOWqW",
        "colab": {}
      },
      "source": [
        "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "# Загружаем предварительно обученную нейронную сеть Inceptionv3\n",
        "#inception_net = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "trowjU9cOWqV"
      },
      "source": [
        "Создаем составную нейронную сеть на основе VGG16 или inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c74cede1-b6d8-4337-fdd0-616160d8af46",
        "id": "BuPv0hi8OWqR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "source": [
        "vgg16_net.summary()\n",
        "#inception_net.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrTSLmcSOWqO",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# Добавляем в модель сеть VGG16 вместо слоя\n",
        "model.add(vgg16_net)\n",
        "#model.add(inception_net)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YFuiGEMWOWqO"
      },
      "source": [
        "Компилируем составную нейронную сеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "miDhM6UROWqL",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VP-30ILDOWqL"
      },
      "source": [
        "Создаем генератор изображений\n",
        "Генератор изображений создается на основе класса ImageDataGenerator. Генератор делит значения всех пикселов изображения на 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JB0piaBKOWqI",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1BFM-fsPOWqH"
      },
      "source": [
        "Генератор данных для обучения на основе изображений из каталога"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "be4a2004-b51b-47e3-b8ac-772216a14ca2",
        "id": "7wk-s2FgOWqC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14034 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uo0LpxltOWqA"
      },
      "source": [
        "Генератор данных для проверки на основе изображений из каталога"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rk9FlvhHOWp9",
        "outputId": "764742e6-8dbf-4366-ce72-8d1b56427a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 126 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXoH4QU-OWp9"
      },
      "source": [
        "Генератор данных для тестирования на основе изображений из каталога"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DorrUoFEOWp6",
        "outputId": "4511ed8d-4051-443d-a514-91fcacbddb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 126 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mR6dVH0rOWp5"
      },
      "source": [
        "Обучаем модель с использованием генераторов\n",
        "train_generator - генератор данных для обучения\n",
        "\n",
        "validation_data - генератор данных для проверки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mbxMs3vAOWp2",
        "outputId": "41898a45-fda0-48a7-942f-ba20fe0918f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 46s 570ms/step - loss: 1.2450 - acc: 0.5181 - val_loss: 0.5582 - val_acc: 0.7708\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 38s 476ms/step - loss: 0.6625 - acc: 0.7582 - val_loss: 0.4119 - val_acc: 0.8333\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 38s 477ms/step - loss: 0.4813 - acc: 0.8309 - val_loss: 0.3464 - val_acc: 0.8854\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 38s 477ms/step - loss: 0.4350 - acc: 0.8465 - val_loss: 0.3665 - val_acc: 0.8542\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 38s 477ms/step - loss: 0.3838 - acc: 0.8605 - val_loss: 0.3101 - val_acc: 0.8646\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 38s 476ms/step - loss: 0.3566 - acc: 0.8797 - val_loss: 0.2759 - val_acc: 0.8854\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 38s 476ms/step - loss: 0.3133 - acc: 0.8980 - val_loss: 0.2410 - val_acc: 0.8958\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 38s 476ms/step - loss: 0.2938 - acc: 0.9008 - val_loss: 0.2446 - val_acc: 0.8854\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 38s 477ms/step - loss: 0.2729 - acc: 0.9051 - val_loss: 0.2355 - val_acc: 0.8854\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 38s 477ms/step - loss: 0.2609 - acc: 0.9082 - val_loss: 0.2158 - val_acc: 0.9062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f64a7b56470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i5hojfKtOWp0",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fidafu3yOWpx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41797bd3-fa2b-4863-a870-d8310f33651a"
      },
      "source": [
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 93.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1UYemABVD0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "11b265c9-302d-4750-e26b-c03f29c81bca"
      },
      "source": [
        "\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.python.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "image_file_name = test_dir + '/sea/20212.jpg'\n",
        "img = image.load_img(image_file_name, target_size=(150, 150))\n",
        "#plt.imshow(img)\n",
        "#plt.show()\n",
        "\n",
        "xxxxx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "\n",
        "xxxxx = xxxxx.reshape((1,) + xxxxx.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "xxxxx = preprocess_input(xxxxx)\n",
        "preds = model.predict(xxxxx)\n",
        "print('Predicted:', preds)\n",
        "\t\n",
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "#model.save_weights(name)\n",
        "print(name + \" saved model to disk\")\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: [[7.5445092e-22 0.0000000e+00 2.9449462e-04 9.0023826e-16 9.9970549e-01\n",
            "  1.5608179e-35]]\n",
            "Аккуратность на тестовых данных: 93.75%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1b018bc525fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#model.save_weights(name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
          ]
        }
      ]
    }
  ]
}